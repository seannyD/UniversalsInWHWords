paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip --bbox '",
0,0,w0*bp2mm,h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l*bp2mm, " ",
-t*bp2mm, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
w0 = 210
h0 = 297.1
w = 152.35
h = 228.55
l = (w0 - w)/2
t = (h0 - h)/2
w0 - (2*l)
bp2mm = 2.83467
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l*bp2mm, " ",
-t*bp2mm, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
library(ape)
rtree(10)
t = rtree(10)
d = matrix(rnorm(100),nrow=10)
t
plot(t)
d
d[upper.tri(d)] = d[lower.tri(d)]
diag(d) = 0
library(ecodist)
??patristic
vcov(t)
?vcov
source("http://www.bioconductor.org/biocLite.R")
biocLite("msa")
stringdist("hound","hand", method = 'osa')
library(stringdist)
stringdist("hound","hand", method = 'osa')
?"stringdist"
12/28
library(ngramr)
install.packages('ngramr')
library(ngramr)
install.packages("~/Desktop/ngramr_1.4.5.gz", repos = NULL)
install.packages("~/Desktop/ngramr_1.4.5.tgz", repos = NULL)
install.packages("~/Desktop/ngramr_1.4.5.tar.gz", repos = NULL)
library(ngramr)
?ngram
x = list()
x[[1]] = list(1, 2, 3)
x[[2]] = list(4, 5, 6)
x[[3]] = list(7, 8, 9)
y = do.call(rbind, x)
y
y = matrix(1:9,nrow=3)
y[1,]
y
x = list()
x[[1]] = list(1, 2, 3)
x[[2]] = list(4, 5, 6)
x[[3]] = list(7, 8, 9)
y = do.call(rbind, x)
y
y[1,]
typeof(y)
y = as.matrix(y)
y
y[1,]
unlist(y)
?do.call
z = matrix(1:9,nrow=3)
typeof(z)
y = do.call(function(X){rbind(unlist(X))}, x)
?do.call
rbindunlist = function(X){rbind(unlist(X))}
do.call(rbindunlist, x)
x
unlist(x)
lapply(x, unlist)
do.call(rbind,lapply(x, unlist))
typeof(do.call(rbind,lapply(x, unlist)))
y = do.call(rbind, lapply(x, unlist))
y[1,]
library(lme4)
cite(lme4)
cite("lme4")
?lme4
?cite
d = read.table("~/Desktop/jaeger.tab", stringsAsFactors = F, header=T,sep='\t')
head(d)
names(d)
image(d[17:40,17:40])
17:40
d[17:40,17:40]
image(as.matrix(d[17:40,17:40]))
heatmap(as.matrix(d[17:40,17:40]))
rownames(d) = colnames(d)
image(as.matrix(d[17:40,17:40]))
heatmap(as.matrix(d[17:40,17:40]))
d = read.table("~/Desktop/jaeger.tab", stringsAsFactors = F, header=T,sep='\t')
rownames(d) = colnames(d)
image(as.matrix(d[17:40,17:40]))
heatmap(as.matrix(d[17:40,17:40]))
library(ape)
t1 = rtree()
t2 = rtree()
t2 = compute.brlen(t1)
t1 = rtree(10)
t2 = compute.brlen(t1)
plot(t1)
plot(t2)
plot(t1$edge.length, t2$edge.length)
?is.ultrametric
library(ape)
?ace
matrix(c(0, 1, 1, 0), 2)
matrix(c(0, 1, 2, 1, 0, 3, 2, 3, 0), 3))
matrix(c(0, 1, 2, 1, 0, 3, 2, 3, 0), 3)
char2<-c(3,3,1,2,1,1,3,3,3,3,2,2,2,3)
names(char2)<- geotree$tip.label
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
geotree <- read.nexus("geospiza.nex")
geotree <- rtree(14)
char2<-c(3,3,1,2,1,1,3,3,3,3,2,2,2,3)
names(char2)<- geotree$tip.label
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
transitions <- matrix (c(0, 1, 2, 1, 0, 3, 2, 4, 0), nrow=3)
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
CUSreconstruction
matrix (c(0, 1, 2, 1, 0, 3, 2, 4, 0), nrow=3)
transitions <- matrix (c(0, -1, 2, 1, 0, 3, 2, 4, 0), nrow=3)
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
transitions <- matrix (c(0, 0, 2, 1, 0, 3, 2, 4, 0), nrow=3)
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
warnings()
CUSreconstruction
transitions <- matrix (c(0, 0, NA, 1, 0, 3, 2, 4, 0), nrow=3)
CUSreconstruction <- ace(char2, geotree, type="discrete", model=transitions)
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
initial.e = getWordListEntropy(d.wh.possible.initial.m, T)
non.initial.e = getWordListEntropy(d.wh.possible.non.initial.m, T)
hist(initial.e)
hist(non.initial.e)
table(families.d.wh.possible.initial)
sort(table(families.d.wh.possible.initial))
sort(table(d.wh.possible.non.initial.m))
sort(table(families.d.wh.possible.non.initial))
sort(table(families.d.wh.possible.initial))
initial.e[families.d.wh.possible.initial=='Nakh-Daghestanian']
initial.e[families.d.wh.possible.initial=='Nakh-Daghestanian',]
initial.e[families.d.wh.possible.initial=='Nakh-Daghestanian']
table(families.d.wh.possible.initial)
initial.e[families.d.wh.possible.non.initial=='Nakh-Daghestanian']
head(families.d.wh)
head(names(d.wh.possible.initial.m))
head(colnames(d.wh.possible.initial.m))
head(d.wh.possible.non.initial.glotto)
#data that has question words, all columns
d.wh = alldata[alldata$meaning.id.fixed %in% whwords,]
#variable for analyses - only wh-words words
d.wh.m = data.frame.to.matrix(d.wh)
fam = tapply(l.details$langFam,l.details$glotto,head,n=1)
area = tapply(l.details$area,l.details$glotto,head,n=1)
names2glotto = tapply(d.wh$glotto,d.wh$Language,head,n=1)
d.wh.glotto = names2glotto[colnames(d.wh.m)]
families.d.wh = fam[d.wh.glotto]
areas.d.wh = area[d.wh.glotto]
#library(maps)
#map()
#points(l.details[match(d.wh.glotto ,l.details$glotto),]$longitude,l.details[match(d.wh.glotto ,l.details$glotto),]$latitude,col=2,pch=16)
#Defining variables
#initial.glotto = l.details[l.details$InterrogativePosition=="1 Initial interrogative phrase" & !is.na(l.details$InterrogativePosition) & l.details$InterrogativePosition!="",]$glotto
#non.initial.glotto = l.details[l.details$InterrogativePosition!="1 Initial interrogative phrase" & !is.na(l.details$InterrogativePosition) & l.details$InterrogativePosition!="",]$glotto
#d.wh.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% initial.glotto,]
#d.wh.initial.m = data.frame.to.matrix(d.wh.initial)
#d.wh.non.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% non.initial.glotto,]
#d.wh.non.initial.m = data.frame.to.matrix(d.wh.non.initial)
#Define variables with grammars positioning info
#initial.grammar.glotto = l.details[l.details$walsandgrammars=="1 Initial interrogative phrase" & !is.na(l.details$walsandgrammars) & l.details$walsandgrammars!="",]$glotto
#non.initial.grammar.glotto = l.details[l.details$walsandgrammars=="2 Not initial interrogative phrase" & !is.na(l.details$walsandgrammars) & l.details$walsandgrammars!="",]$glotto
#d.wh.grammar.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% initial.grammar.glotto,]
#d.wh.grammar.initial.m = data.frame.to.matrix(d.wh.grammar.initial)
#d.wh.grammar.non.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% non.initial.grammar.glotto,]
#d.wh.grammar.non.initial.m = data.frame.to.matrix(d.wh.grammar.non.initial)
#Define variables with possible positioning info
initial.possible.glotto = l.details[l.details$qpos=="1 Initial interrogative phrase" & !is.na(l.details$qpos) & l.details$qpos!="",]$glotto
non.initial.possible.glotto = l.details[l.details$qpos=="2 Not initial interrogative phrase" & !is.na(l.details$qpos) & l.details$qpos!="",]$glotto
d.wh.possible.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% initial.possible.glotto,]
d.wh.possible.initial.m = data.frame.to.matrix(d.wh.possible.initial)
d.wh.possible.non.initial = alldata[alldata$meaning.id.fixed %in% whwords & alldata$glotto %in% non.initial.possible.glotto,]
d.wh.possible.non.initial.m = data.frame.to.matrix(d.wh.possible.non.initial)
d.wh.possible.initial.glotto = names2glotto[colnames(d.wh.possible.initial.m)]
d.wh.possible.non.initial.glotto = names2glotto[colnames(d.wh.possible.non.initial.m)]
families.d.wh.possible.initial = fam[d.wh.possible.initial.glotto]
areas.d.wh.possible.initial = area[d.wh.possible.initial.glotto]
families.d.wh.possible.non.initial = fam[d.wh.possible.non.initial.glotto]
areas.d.wh.possible.non.initial = area[d.wh.possible.non.initial.glotto]
head(d.wh.possible.non.initial.glotto)
head(d.wh.possible.initial.glotto)
d.wh.possible.initial.glotto[1:3,1:10]
d.wh.possible.initial[1:3,1:10]
d.wh.possible.initial.m[1:3,1:10]
head()
head(families.d.wh.possible.initial)
head(initial.e)
head(families.d.wh.possible.initial)
sort(table(families.d.wh.possible.initial))
sort(table(families.d.wh.possible.non.initial))
non.initial.e[families.d.wh.possible.non.initial=='Nakh-Daghestanian']
mean(initial.e)
mean(non.initial.e)
par(mfrow=c(1,2))
hist(initial.e, breaks=20)
hist(non.initial.e, breaks=20)
non.initial.e[non.initial.e==0]
d.wh.m[,'Aymara']
d.wh.m[,'Bengali']
d.wh.m[,'Hindi']
families.d.wh.possible.non.initial[which(non.initial.e==0)]
resultsFile = "tmp.txt"
non.initial.e[non.initial.e==0]
lx = names(non.initial.e[non.initial.e==0])
lx
d.wh.possible.non.initial = d.wh.possible.non.initial[,!names(d.wh.possible.non.initial) %in% lx]
head(families.d.wh.possible.non.initial)
names2glotto
names2glotto[lx]
families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[!names(families.d.wh.possible.non.initial) %in% names2glotto[lx]]
dim(d.wh.possible.initial.m)
d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,!names(d.wh.possible.non.initial.m) %in% lx]
families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[!names(families.d.wh.possible.non.initial) %in% names2glotto[lx]]
dim(d.wh.possible.initial.m)
colnames(d.wh.possible.non.initial.m)
names(d.wh.possible.non.initial.m)
dim(d.wh.possible.non.initial.m)
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
dim(d.wh.m)
apply(d.wh.m,1,function(X){sum(!is.na(X))})
apply(d.wh.m,2,function(X){sum(!is.na(X))})
apply(d.random.m,2,function(X){sum(!is.na(X))})
hist(apply(d.random.m,2,function(X){sum(!is.na(X))}))
hist(apply(d.random.m,2,function(X){sum(!is.na(X))}))
x = apply(d.random.m,2,function(X){sum(!is.na(X))})
hist(x)
sum(x>1000)
sum(x>900)
names(d.wh.possible.non.initial.m)
colnames(d.wh.possible.non.initial.m)
!colnames(d.wh.possible.non.initial.m) %in% lx
non.initial.e = getWordListEntropy(d.wh.possible.non.initial.m, T)
non.initial.e[non.initial.e==0]
lx = names(non.initial.e[non.initial.e==0])
!colnames(d.wh.possible.non.initial.m) %in% lx
d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,!colnames(d.wh.possible.non.initial.m) %in% lx]
names(families.d.wh.possible.non.initial)
names(families.d.wh.possible.non.initial) %in% names2glotto[lx]
families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[!names(families.d.wh.possible.non.initial) %in% names2glotto[lx]]
resultsFile = "tmp.txt"
number.of.perms = 20000
number.of.random.samples = 100
runComparison.randomSample(d.wh.possible.initial.m,d.wh.possible.non.initial.m,families.d.wh.possible.initial,families.d.wh.possible.non.initial,"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_TMPTMPTMP",T)
190/20000
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
dx = data.frame(e = c(initial.e,noninitial.e),
qpos = c(rep('initial',length(initial.e)),rep('non.initial',length(non.initial.e))),
family = c(families.d.wh.possible.initial,families.d.wh.possible.non.initial)
area = c(areas.d.wh.possible.initial, areas.d.wh.possible.non.initial)
)
dx = data.frame(e = c(initial.e,noninitial.e),
qpos = c(rep('initial',length(initial.e)),rep('non.initial',length(non.initial.e))),
family = c(families.d.wh.possible.initial,families.d.wh.possible.non.initial),
area = c(areas.d.wh.possible.initial, areas.d.wh.possible.non.initial)
)
initial.e = getWordListEntropy(d.wh.possible.initial.m, T)
non.initial.e = getWordListEntropy(d.wh.possible.non.initial.m, T)
dx = data.frame(e = c(initial.e,noninitial.e),
qpos = c(rep('initial',length(initial.e)),rep('non.initial',length(non.initial.e))),
family = c(families.d.wh.possible.initial,families.d.wh.possible.non.initial),
area = c(areas.d.wh.possible.initial, areas.d.wh.possible.non.initial)
)
dx = data.frame(e = c(initial.e,non.initial.e),
qpos = c(rep('initial',length(initial.e)),rep('non.initial',length(non.initial.e))),
family = c(families.d.wh.possible.initial,families.d.wh.possible.non.initial),
area = c(areas.d.wh.possible.initial, areas.d.wh.possible.non.initial)
)
head(dx)
library(lme4)
hist(dx$e)
dx$e.norm = dx$e - mean(dx$e)
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx)
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx)
anova(m0,m1)
ranef(m1)
dotplot(ranef(m1))
library(lattice)
dotplot(ranef(m1))
summary(m0)
summary(m1)
library(influence.ME)
influence(m1)
infl = influence(m1, obs=T)
infl
plot(infl)
infl$alt.test
estex(m1)
cooks.distance(m1)
cooks.distance.estex(m1)
cooks.distance(infl)
plot(cooks.distance(infl))
which(infl>0.08)
cd = cooks.distance(infl)
cd[cd>0.08]
which(cd>0.08)
dx[which(cd>0.08),]
dim(dx)
summary(m1)
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx[rownames(dx)!='Shipibo-Conibo'])
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx[rownames(dx)!='Shipibo-Conibo',])
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx[rownames(dx)!='Shipibo-Conibo',])
summary(m1)
anova(m0,m1)
dx[which(cd>0.06),]
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=!dx[rownames(dx)%in%c('Shipibo-Conibo','Aymara'),])
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx[rownames(dx)%in%c('Shipibo-Conibo','Aymara'),])
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx[!rownames(dx)%in%c('Shipibo-Conibo','Aymara'),])
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx[!rownames(dx)%in%c('Shipibo-Conibo','Aymara'),])
anova(m0,m1)
summary(m1)
dim(dx)
dim(dx[!rownames(dx)%in%c('Shipibo-Conibo','Aymara'),])
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx)
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx)
plot(dx$e.norm, predict(m1))
table(dx$qpos)
m0 = lmer(e.norm ~ 1 + (1|family) + (1|area), data=dx[dx$e>0,])
m1 = lmer(e.norm ~ 1 + qpos + (1|family) + (1|area), data=dx[dx$e>0,])
anova(m0,m1)
summary(m1)
m0 = lmer(e.norm ~ 1 + (1+qpos|family) + (1+qpos|area), data=dx[dx$e>0,])
m1 = lmer(e.norm ~ 1 + qpos + (1+qpos|family) + (1+qpos|area), data=dx[dx$e>0,])
anova(m0,m1)
summary(m1)
m0 = lmer(e.norm ~ 1 + (1+qpos|family) + (1+qpos|area), data=dx)
m1 = lmer(e.norm ~ 1 + qpos + (1+qpos|family) + (1+qpos|area), data=dx)
anova(m0,m1)
summary(m1)
dx
library(party)
party(e~qpos, data=dx)
cx = ctree(e~qpos, data=dx)
plot(tx)
plot(cx)
cx = ctree(e~qpos+family+area, data=dx)
plot(cx)
cx
cx = ctree(e~qpos, data=dx, controls = ctree_control(mincriterion = 0.8))
plot(cx)
cx = ctree(e~qpos, data=dx, controls = ctree_control(mincriterion = 0.5))
plot(cx)
cx = ctree(e~qpos, data=dx, controls = ctree_control(mincriterion = 0.2))
plot(cx)
cx = ctree(e~qpos, data=dx, controls = ctree_control(mincriterion = 0.4))
plot(cx)
cx = ctree(e~qpos, data=dx, controls = ctree_control(mincriterion = 0.3))
plot(cx)
cx = ctree(e~qpos+family+area, data=dx, controls = ctree_control(mincriterion = 0.3))
plot(cx)
names2glotto[colnames(d.wh.possible.non.initial.m)]
original.initial
names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.langs = c("olda1245","polc1243","haus1257","gaww1239","iraq1241","tari1263","mapu1245","mash1270","wapi1253","waur1244","trin1274","yavi1244","wayu1243","igna1246","swah1253","khas1269","chew1245","viet1252","tuam1242","rapa1244","rotu1241","hawa1245","maor1246","taki1248","indo1316","plat1254","sout2996","colo1256","chac1249","basq1248","waiw1244","enap1235","maqu1238","macu1259","gali1262","cayu1262","bari1297","chib1270","nort2972","epen1239","onaa1245","tehu1242","cofa1242","telu1262","tami1289","moco1246","pila1245","toba1269","nort2938","hmon1333","limo1249","roma1329","tokh1242","tokh1243","gheg1238","nege1244","croa1245","east2295","nucl1235","bret1244","bulg1262","west2369","russ1263","stan1288","maha1287","beng1280","mara1378","panj1256","lowe1385","west2376","dutc1256","oldh1241","sara1340","sese1246","stan1293","roma1327","iton1250","nucl1643","agua1253","karo1304","qawa1238","leng1262","nucl1655","iyow1239","maca1260","niva1238","wich1264","kekc1242","tzot1259","mose1249","movi1243","hupd1244","bezh1248","arch1244","nepa1252","kain1272","zaca1242","mezq1235","paez1247","guri1247","pano1254","yami1256","chac1251","ship1254","yagu1244","puel1244","puin1248","pume1238","imba1240","cent2050","seri1257","nung1282","tibe1272","mana1288","mand1415","arao1248","cavi1250","esee1248","taca1256","lang1316","lakk1238","nucl1241","mula1253","gela1265","shan1277","kami1255","sout2746","suii1243","minz1236","chad1240","maon1241","luuu1242","thai1261","khun1259","nort2740","nung1283","trum1247","nucl1649","sion1247","tuyu1244","oroq1238","ache1246","east2555","siri1273","para1311","waya1270","yaku1245","erzy1239","komi1268","east2328","nene1249","udmu1245","nort2671","esto1258","finn1318","khan1273","mans1258","selk1253","hung1274","kild1236","chip1262","high1278","yaqu1251","noot1238","waor1240","yama1264","yano1262","nina1238","kett1243","yuwa1244","ayor1240","zuni1245")
names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.non.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
resultsFile
resultsFile = "tmp.txt"
number.of.perms = 20000
number.of.random.samples = 100
runComparison.randomSample(
original.d.wh.possible.initial.m,
original.d.wh.possible.non.initial.m,
original.families.d.wh.possible.initial,
original.families.d.wh.possible.non.initial,
"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_ORIG_TMPTMPTMP",T)
original.langs = c("olda1245","polc1243","haus1257","gaww1239","iraq1241","tari1263","mapu1245","mash1270","wapi1253","waur1244","trin1274","yavi1244","wayu1243","igna1246","swah1253","khas1269","chew1245","viet1252","tuam1242","rapa1244","rotu1241","hawa1245","maor1246","taki1248","indo1316","plat1254","sout2996","colo1256","chac1249","basq1248","waiw1244","enap1235","maqu1238","macu1259","gali1262","cayu1262","bari1297","chib1270","nort2972","epen1239","onaa1245","tehu1242","cofa1242","telu1262","tami1289","moco1246","pila1245","toba1269","nort2938","hmon1333","limo1249","roma1329","tokh1242","tokh1243","gheg1238","nege1244","croa1245","east2295","nucl1235","bret1244","bulg1262","west2369","russ1263","stan1288","maha1287","beng1280","mara1378","panj1256","lowe1385","west2376","dutc1256","oldh1241","sara1340","sese1246","stan1293","roma1327","iton1250","nucl1643","agua1253","karo1304","qawa1238","leng1262","nucl1655","iyow1239","maca1260","niva1238","wich1264","kekc1242","tzot1259","mose1249","movi1243","hupd1244","bezh1248","arch1244","nepa1252","kain1272","zaca1242","mezq1235","paez1247","guri1247","pano1254","yami1256","chac1251","ship1254","yagu1244","puel1244","puin1248","pume1238","imba1240","cent2050","seri1257","nung1282","tibe1272","mana1288","mand1415","arao1248","cavi1250","esee1248","taca1256","lang1316","lakk1238","nucl1241","mula1253","gela1265","shan1277","kami1255","sout2746","suii1243","minz1236","chad1240","maon1241","luuu1242","thai1261","khun1259","nort2740","nung1283","trum1247","nucl1649","sion1247","tuyu1244","oroq1238","ache1246","east2555","siri1273","para1311","waya1270","yaku1245","erzy1239","komi1268","east2328","nene1249","udmu1245","nort2671","esto1258","finn1318","khan1273","mans1258","selk1253","hung1274","kild1236","chip1262","high1278","yaqu1251","noot1238","waor1240","yama1264","yano1262","nina1238","kett1243","yuwa1244","ayor1240","zuni1245")
original.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.non.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.d.wh.possible.initial.m = d.wh.possible.initial.m[,original.intial]
original.d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,original.non.intial]
original.families.d.wh.possible.initial = families.d.wh.possible.initial[original.initial]
original.families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[original.non.initial]
runComparison.randomSample(
original.d.wh.possible.initial.m,
original.d.wh.possible.non.initial.m,
original.families.d.wh.possible.initial,
original.families.d.wh.possible.non.initial,
"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_ORIG_TMPTMPTMP",T)
original.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.non.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.d.wh.possible.initial.m = d.wh.possible.initial.m[,original.intial]
original.d.wh.possible.initial.m = d.wh.possible.initial.m[,original.initial]
original.d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,original.non.intial]
original.d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,original.non.initial]
original.families.d.wh.possible.initial = families.d.wh.possible.initial[original.initial]
original.families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[original.non.initial]
runComparison.randomSample(
original.d.wh.possible.initial.m,
original.d.wh.possible.non.initial.m,
original.families.d.wh.possible.initial,
original.families.d.wh.possible.non.initial,
"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_ORIG_TMPTMPTMP",T)
table(original.initial)
table(original.non.initial)
colnames(d.wh.possible.non.initial.m)
length(colnames(d.wh.possible.non.initial.m))
length(colnames(d.wh.possible.initial.m))
original.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.non.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
table(original.non.initial)
table(original.initial)
original.initial = names2glotto[colnames(d.wh.possible.initial.m)] %in% original.langs
original.non.initial = names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
original.d.wh.possible.initial.m = d.wh.possible.initial.m[,original.initial]
original.d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,original.non.initial]
original.families.d.wh.possible.initial = families.d.wh.possible.initial[original.initial]
original.families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[original.non.initial]
table(original.initial)
table(original.non.initial)
runComparison.randomSample(
original.d.wh.possible.initial.m,
original.d.wh.possible.non.initial.m,
original.families.d.wh.possible.initial,
original.families.d.wh.possible.non.initial,
"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_ORIG_TMPTMPTMP",T)
581/20000
sum(!original.initial)
sum(!original.initial)+ sum(!original.non.initial)
new.initial = !names2glotto[colnames(d.wh.possible.initial.m)] %in% original.langs
new.non.initial = !names2glotto[colnames(d.wh.possible.non.initial.m)] %in% original.langs
new.d.wh.possible.initial.m = d.wh.possible.initial.m[,new.initial]
new.d.wh.possible.non.initial.m = d.wh.possible.non.initial.m[,new.non.initial]
new.families.d.wh.possible.initial = families.d.wh.possible.initial[new.initial]
new.families.d.wh.possible.non.initial = families.d.wh.possible.non.initial[new.non.initial]
e.initial.new = getWordListEntropy(new.d.wh.possible.initial.m,T)
e.non.initial.new = getWordListEntropy(new.d.wh.possible.non.initial.m,T)
hist(e.initial.new)
hist(e.non.initial.new)
e.non.initial.new[e.non.initial.new<0]
e.non.initial.new[e.non.initial.new=0]
e.non.initial.new[e.non.initial.new==0]
e.non.initial.new[e.non.initial.new<0.2]
new.families.d.wh.possible.initial
new.families.d.wh.possible.non.initial
names2glotto[names(e.non.initial.new[e.non.initial.new<0.2])]
new.families.d.wh.possible.non.initial[e.non.initial.new<0.2]
x = unique(alldata$Language)
x[grepl("dialect",x)]
new.families.d.wh.possible.non.initial[e.non.initial.new<0.2]
names2glotto[names(e.non.initial.new[e.non.initial.new<0.2])]
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
####################################
# Run the permutations#
####################################
resultsFile='tmp2.txt'
number.of.perms = 20000
number.of.random.samples = 100# number of sets of random concept sets chosen in the comparison permutation for non-wh concepts.
runComparison.randomSample(d.wh.possible.initial.m,d.wh.possible.non.initial.m,families.d.wh.possible.initial,families.d.wh.possible.non.initial,"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments_TMPTMPTMP",T)
4535 / 20000

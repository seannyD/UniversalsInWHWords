numWordsPerLang
hist(numWordsPerLang)
min(numWordsPerLang)
numWordsPerLang = apply(d.wh.m,2, function(X){
x = unlist(strsplit(X,";"))
x = x[nchar(x)>0]
length(x)
})
min(numWordsPerLang)
d.wh.m[,1:3]
d.wh.m[,1:8]
numWordsPerLang.random = apply(d.random.m,2, function(X){
x = unlist(strsplit(X,";"))
x = x[nchar(x)>0]
length(x)
})
hist(numWordsPerLang.random)
dx = d.random.m
n = numWordsPerLang
dim(d.wh.m)
sum(d.wh.m=='')
sum(d.wh.m=='',na.rm=T)
sum(is.na(d.wh.m))
numNA = apply(d.wh.m,2,function(X){sum(is.na(X))})
numNA
hist(numNA)
d.wh.m[,"Tsimshian"]
X = d.wh.m[,"Tsimshian"]
unlist(strsplit(X,";"))
x[nchar(x)>0]
x = unlist(strsplit(X,";"))
x[nchar(x)>0]
x[nchar(x)>0 & !is.na(x)]
numWordsPerLang = apply(d.wh.m,2, function(X){
x = unlist(strsplit(X,";"))
x = x[nchar(x)>0 & !is.na(x)]
length(x)
})
hist(numWordsPerLang)
d.wh.m[,which(numNA==25)]
d.wh.m[,which(numNA==24)]
which(numNA==24)
numNA
max(numNA)
d.wh.m[,which(numWordsPerLang==24)]
d.wh.m[,which(numWordsPerLang==25)]
dx[sample(1:nrow(dx)),]
dx = dx[sample(1:nrow(dx)),]
dx2 = apply(dx,2, function(X){
x = unlist(strsplit(X,";"))
x[!is.na(x)]
})
dx2[[1]]
mapply(dx2,n, function(t,i){t[1:i]})
?mapply
mapply(function(t,i){t[1:i]},dx2,n)
tail(numWordsPerLang)
z = mapply(function(t,i){t[1:i]},dx2,n)
getWordListEntropy(z)
firstSegment = T
mapply(function(t,i,firstSegment){
sx = t[1:i]
if(firstSegment){
sx = substr(sx,1,1)
}
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
},dx2,n,firstSegment)
firstSegment=F
mapply(function(t,i,firstSegment){
sx = t[1:i]
if(firstSegment){
sx = substr(sx,1,1)
}
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
},dx2,n,firstSegment)
t = dx2
dim(dx2)
dx = dx[sample(1:nrow(dx)),]
dx2 = apply(dx,2, function(X){
x = unlist(strsplit(X,";"))
x[!is.na(x)]
})
dim(dx2)
length(dx2)
firstSegment
sapply(1:length(n), function(i){
sx = dx[1:n[i],i]
sx = substr(sx,1,1)
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
})
sampleSameNumberOfLangs = function(dx, n,firstSegment=F){
# put rows into random order
dx = dx[sample(1:nrow(dx)),]
#dx2 = apply(dx,2, function(X){
#  x = unlist(strsplit(X,";"))
#  x[!is.na(x)]
#  })
if(firstSegment){
return(sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[1:n[i],i],";"))
sx = sx[!is.na(sx)]
sx = substr(sx,1,1)
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}))
} else{
return(sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[1:n[i],i],";"))
sx = sx[!is.na(sx)]
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}))
}
}
sampleSameNumberOfLangs(d.random.m,numWordsPerLang)
sampleSameNumberOfLangs(d.random.m,rep(1,226))
sampleSameNumberOfLangs(d.random.m,rep(1,226),T)
sampleSameNumberOfLangs = function(dx, n,firstSegment=F){
# put rows into random order
dx = dx[sample(1:nrow(dx)),]
#dx2 = apply(dx,2, function(X){
#  x = unlist(strsplit(X,";"))
#  x[!is.na(x)]
#  })
if(firstSegment){
return(sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
sx = substr(sx,1,1)
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}))
} else{
return(sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}))
}
}
sampleSameNumberOfLangs(d.random.m,numWordsPerLang)
sampleSameNumberOfLangs(d.random.m,rep(1,226))
sampleSameNumberOfLangs(d.random.m,rep(1,226),T)
sampleSameNumberOfLangs(d.random.m,rep(2,226),T)
which(is.nan(sampleSameNumberOfLangs(d.random.m,rep(2,226),T)))
x = sampleSameNumberOfLangs(d.random.m,rep(2,226),T)
x
x = sampleSameNumberOfLangs(d.random.m,rep(2,226),T)
x
which(is.nan(x))
sapply(1:length(n), function(i, firstSegment){
sx = unlist(strsplit(dx[,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
if(firstSegment){
sx = substr(sx,1,1)
}
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}, firstSegment=firstSegment)
firstSegment
firstSegment = T
sapply(1:length(n), function(i, firstSegment){
sx = unlist(strsplit(dx[,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
if(firstSegment){
sx = substr(sx,1,1)
}
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}, firstSegment=firstSegment)
getWordListEntropy(dx[1:9,],firstSegment = firstSegment)
sampleSameNumberOfLangs = function(dx, n,firstSegment=F){
# put rows into random order
dx = dx[sample(1:nrow(dx)),]
matchConcept.E = mean(getWordListEntropy(dx[1:9,],firstSegment = firstSegment))
matchN.E =
mean(sapply(1:length(n), function(i, firstSegment){
sx = unlist(strsplit(dx[,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
if(firstSegment){
sx = substr(sx,1,1)
}
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
myEntropy(table(charmap[segs]))
}, firstSegment=firstSegment))
return(c(matchConcept.E,matchN.E))
}
matchedNPerm.means = replicate(n = 3, sampleSameNumberOfLangs(d.random.m,numWordsPerLang))
matchedNPerm.means
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
})
ranOrder = sample(1:nrow(dx))
matchConcept.E = mean(
getWordListEntropy(
dx[ranOrder[1:9],],
firstSegment = firstSegment))
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
})
getE = function(sx){
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
return(myEntropy(table(charmap[segs])))
}
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
return(c(e.all,e.first))
})
apply(matchN.E,1,mean)
matchN.E =
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
return(c(e.all,e.first))
})
apply(matchN.E,1,mean)
getE = function(sx){
segs = unlist(strsplit(sx,""))
uSegs = unique(segs)
uSegs = uSegs[uSegs!=""]
charmap = 1:length(uSegs)
names(charmap) = uSegs
return(myEntropy(table(charmap[segs])))
}
sampleSameNumberOfLangs = function(dx, n,firstSegment=F){
# put rows into random order
ranOrder = sample(1:nrow(dx))
matchConcept.E.all = mean(
getWordListEntropy(
dx[ranOrder[1:9],],
firstSegment = F))
matchConcept.E.first = mean(
getWordListEntropy(
dx[ranOrder[1:9],],
firstSegment = T))
matchN.E =
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
return(c(e.all,e.first))
})
apply(matchN.E,1,mean)
return(c(matchConcept.E.all,matchConcept.E.first,
apply(matchN.E,1,mean)))
}
sampleSameNumberOfLangs = function(dx, n){
# put rows into random order
ranOrder = sample(1:nrow(dx))
matchConcept.E.all = mean(
getWordListEntropy(
dx[ranOrder[1:9],],
firstSegment = F))
matchConcept.E.first = mean(
getWordListEntropy(
dx[ranOrder[1:9],],
firstSegment = T))
matchN.E =
sapply(1:length(n), function(i){
sx = unlist(strsplit(dx[ranOrder,i],";"))
sx = sx[!is.na(sx)]
sx = sx[1:n[i]]
e.all = getE(sx)
# first segs
sx = substr(sx,1,1)
e.first = getE(sx)
return(c(e.all,e.first))
})
apply(matchN.E,1,mean)
return(c(matchConcept.E.all,matchConcept.E.first,
apply(matchN.E,1,mean)))
}
matchedNPerm.means = replicate(n = 3, sampleSameNumberOfLangs(d.random.m,numWordsPerLang,T))
matchedNPerm.means = replicate(n = 3, sampleSameNumberOfLangs(d.random.m,numWordsPerLang))
matchedNPerm.means
matchedNPerm.means = replicate(n = 3, sampleSameNumberOfLangs(d.random.m,numWordsPerLang))
wh.Mean.First = mean(getWordListEntropy(d.wh.m,T))
wh.Mean.All = mean(getWordListEntropy(d.wh.m,F))
sum(matchedNPerm.means[1,]> wh.Mean.All)
sum(matchedNPerm.means[1,]<= wh.Mean.All)
sum(matchedNPerm.means[1,]<= wh.Mean.All)
# wh vs matched concept, first
sum(matchedNPerm.means[2,]<= wh.Mean.All)
# wh vs matched N, all
sum(matchedNPerm.means[3,]<= wh.Mean.All)
# wh vs matched N, first
sum(matchedNPerm.means[4,]<= wh.Mean.All)
1/length(permE)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
return(1/length(permE))
} else{
return(p / sum(!is.na(p)))
}
z = realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z),collapse="")
}
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
return(1/length(permE))
} else{
return(p / sum(!is.na(p)))
}
z = realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z),collapse="")
}
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
return(1/length(permE))
} else{
return(p / sum(!is.na(p)))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z),collapse="")
}
getStats(matchedNPerm.means[1,],wh.Mean.All)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
return(1/length(permE))
} else{
return(p / sum(!is.na(p)))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z),collapse="")
}
getStats(matchedNPerm.means[1,],wh.Mean.All)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
p = 1/length(permE)
} else{
return(p / sum(!is.na(p)))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z),collapse="")
}
# wh vs matched concept, all
getStats(matchedNPerm.means[1,],wh.Mean.All)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
p = 1/length(permE)
} else{
return(p / sum(!is.na(p)))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z,collapse=""))
}
# wh vs matched concept, all
getStats(matchedNPerm.means[1,],wh.Mean.All)
getStats(matchedNPerm.means[2,],wh.Mean.All)
getStats(matchedNPerm.means[3,],wh.Mean.First)
getStats(matchedNPerm.means[4,],wh.Mean.First)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
p = paste("< ",1/length(permE),collapse='')
} else{
p = p / sum(!is.na(p))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z,collapse=""))
}
# wh vs matched concept, all
getStats(matchedNPerm.means[1,],wh.Mean.All)
matchedNPerm.means = replicate(
n = 1000,
sampleSameNumberOfLangs(d.random.m,numWordsPerLang))
set.seed(2387)
matchedNPerm.means = replicate(
n = 1000,
sampleSameNumberOfLangs(d.random.m,numWordsPerLang))
write.csv(matchedNPerm.means,"../Results/SimplifiedPhonology/PermutationResults/MatchNPermutation.csv", row.names = F)
wh.Mean.All = mean(getWordListEntropy(d.wh.m,F))
wh.Mean.First = mean(getWordListEntropy(d.wh.m,T))
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
p = paste("< ",1/length(permE),collapse='')
} else{
p = p / sum(!is.na(p))
}
z = (realE - mean(permE)) / sd(permE)
return(paste("p = ",p,", z = ",z,collapse=""))
}
# wh vs matched concept, all
getStats(matchedNPerm.means[1,],wh.Mean.All)
# wh vs matched concept, first
getStats(matchedNPerm.means[2,],wh.Mean.All)
# wh vs matched N, all
getStats(matchedNPerm.means[3,],wh.Mean.First)
# wh vs matched N, first
getStats(matchedNPerm.means[4,],wh.Mean.First)
getStats = function(permE,realE){
p =sum(permE <= realE, na.rm = T)
if(p==0){
p = paste("< ",1/length(permE),collapse='')
} else{
p = p / sum(!is.na(p))
}
z = (realE - mean(permE,na.rm=T)) / sd(permE,na.rm=T)
return(paste("p = ",p,", z = ",z,collapse=""))
}
# wh vs matched concept, all
getStats(matchedNPerm.means[1,],wh.Mean.All)
# wh vs matched concept, first
getStats(matchedNPerm.means[2,],wh.Mean.All)
# wh vs matched N, all
getStats(matchedNPerm.means[3,],wh.Mean.First)
# wh vs matched N, first
getStats(matchedNPerm.means[4,],wh.Mean.First)
matchedNPerm.means[1,] < matchedNPerm.means[3,]
sum(matchedNPerm.means[1,] < matchedNPerm.means[3,])
sum(matchedNPerm.means[2,] < matchedNPerm.means[4,])
sum(matchedNPerm.means[2,] < matchedNPerm.means[4,],na.rm=T)
dim(matchedNPerm.means)
mean(matchedNPerm.means[1,] - matchedNPerm.means[3,],na.rm=T)
mean(matchedNPerm.means[2,] - matchedNPerm.means[4,],na.rm=T)
getStats(matchedNPerm.means[2,],wh.Mean.All)
getStats(matchedNPerm.means[4,],wh.Mean.First)
getStats(matchedNPerm.means[1,],wh.Mean.All)
# wh vs matched concept, first
getStats(matchedNPerm.means[2,],wh.Mean.First)
getStats(matchedNPerm.means[3,],wh.Mean.All)
getStats(matchedNPerm.means[4,],wh.Mean.First)
??pgls
??cor.brownian
??corBrownian

pronouns = as.numeric(c("2.91","2.92","2.93","2.931","2.932","2.933","2.94","2.941","2.942","2.95","2.96"))
he.she.it = as.numeric(c("2.931","2.932","2.933"))
dx = alldata[alldata$meaning.id.fixed %in% he.she.it & !is.na(alldata$meaning.id.fixed),]
he.she.it.words = tapply(dx$word.simple,dx$Language, paste,collapse=';')
sel = (is.na(alldata$word.simple) | nchar(alldata$word.simple)==0) & !is.na(alldata$meaning.id.fixed) & alldata$meaning.id.fixed==2.93
alldata[sel,]$word.simple = he.she.it.words[alldata[sel,]$Language]
langs.with.hesheit = unique(alldata[!is.na(alldata$meaning.id.fixed) & !is.na(alldata$word.simple) & alldata$meaning.id.fixed==2.93,]$Language)
langs.without.hesheit = setdiff(unique(alldata$Language), langs.with.hesheit)
he.she.it.words = he.she.it.words[langs.without.hesheit]
langs.without.hesheit = langs.without.hesheit[!is.na(he.she.it.words)]
he.she.it.words = he.she.it.words[!is.na(he.she.it.words)]
extraPronounRows = data.frame(
meaning.id=2.93,
meaning='he/she/it',
word = he.she.it.words,
Source = "XX",
Language = langs.without.hesheit,
iso = tapply(alldata$iso,alldata$Language,head,n=1)[langs.without.hesheit],
glotto = tapply(alldata$glotto,alldata$Language,head,n=1)[langs.without.hesheit],
borrowed_score = NA,
analyzability = NA,
domain = 2,
word.clean = he.she.it.words,
word.simple = he.she.it.words,
meaning.id.fixed = 2.93
)
alldata = rbind(alldata,extraPronounRows)
########################################
# Restrict data by certain criteria
#Restriction 1. Wh-word count benchmark < 4
#split wh-words (their IDs) by language and specify that those that are NA should be treated as O
list.whwords<-tapply(alldata$meaning.id.fixed, alldata$glotto, countWhWords)
#list.whwords[is.na(list.whwords)]<-0
#Remove all languages that have <4 whwords
#make a list of langauges that have <4 whwords
nowhwords<-names(list.whwords)[list.whwords<4]
#exclude nowhwords from alldata
alldata <- alldata[! alldata$glotto %in% nowhwords,]
#Restriction 2. Word count benchmark >= as wh-words mean count.
#Make function that takes only unique meaning.id and shows the number of languages (length)
get_unique_length_meaning<-function(x){
unique_x<-unique(x)
length(unique_x)
}
#create variable that splits data by how many languages have the meaning.id
meaningsbylang<-tapply(alldata$glotto, alldata$meaning.id.fixed,get_unique_length_meaning)
#create variable that splits data by how many languages have each wh-word
whwordsbylang<-tapply(alldata[alldata$meaning.id.fixed %in% whwords,]$glotto, alldata[alldata$meaning.id.fixed %in% whwords,]$meaning.id.fixed,get_unique_length_meaning)
# define threshold (mean proportion of wh-words available) for word count (id meanings) for langauge to be included.
min_crit<-min(whwordsbylang/(length(unique(alldata$glotto))))
prop_meaningsbylang<-meaningsbylang/(length(unique(alldata$glotto)))
randommeanings<-as.numeric(names(prop_meaningsbylang)[prop_meaningsbylang>=min_crit])
#keep only those lines in alldata that are above min-crit (randommeanings)
alldata <- alldata [alldata$meaning.id.fixed %in% randommeanings | alldata$meaning.id.fixed %in% whwords,]
overlap.lang<-tapply(alldata$Language,alldata$glotto,function(X){length(unique(X))})
overlap.glotto <-names(overlap.lang)[overlap.lang>1]
#
# for(glotto.code in overlap.glotto){
# 	lang.names.associated.with.glotto = unique(alldata[alldata$glotto==glotto.code,]$Language)
# 	# select only data with this glotto code
# 	overlapdata <- alldata[alldata$glotto==glotto.code,]
# 	# and only wh words
# 	overlapdata.wh <- overlapdata[overlapdata$meaning.id.fixed %in% whwords,]
#
# 	# get number of concetps (total)
# 	num.of.concepts <- tapply(overlapdata$meaning.id.fixed,overlapdata$Language,get_unique_length_meaning)
#
# 	# get number of wh words
# 	num.of.Wh.words <- tapply(overlapdata.wh$meaning.id.fixed,overlapdata.wh$Language,get_unique_length_meaning)
#
# 	# get entropy of wh words
# 	# convert to special data frame
# 	overlapdata.matrix <- data.frame.to.matrix(overlapdata.wh)
# 	entropy.wh.words <- getWordListEntropy(overlapdata.matrix)
#
# 	#rank langs by max number of wh words, then max entropy, then max number of concepts
# 	rank_langs = order(num.of.Wh.words,entropy.wh.words,num.of.concepts,decreasing=T)
# 	# choose top ranking language
# 	language_to_keep = names(num.of.Wh.words)[rank_langs[1]]
#
# 	# keep only the chosen language
# 	alldata = alldata[alldata$glotto!=glotto.code | alldata$Language==language_to_keep,]
#
#
# }
allx =alldata[,c("Language",'glotto','Source')]
write.csv(allx[!duplicated(allx),],file = 'LangsInAnalysis.csv', row.names = F, fileEncoding = 'utf-8')
# remove objects we don't need
loaded.functions <- as.vector(lsf.str())
do.not.delete <- c("alldata",'whwords')
rm(list=ls()[! ls() %in% c(loaded.functions,do.not.delete)])
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Processing"))
l.details = read.csv("../Analysis/LangsInAnalysis.csv", fileEncoding = 'utf-8', encoding = 'utf-8', stringsAsFactors = F)
l.details$area = NA
load("~/Documents/MPI/Neandertals_Collab/fossilSept/pca.per.family/autotyp2015-06-09T09-00.rData")
areas = tapply(as.character(autotyp.geography$area),as.character(autotyp.geography$glottolog_LID.2014),head,n=1)
#l.details$area[nchar(l.details$area)<2] = NA
l.details$area = areas[l.details$glotto]
l.details[l.details$glotto=="sout2746",]$area = 'Southeast Asia'
l.details[l.details$glotto=="enap1235",]$area = 'NE South America'
l.details[l.details$glotto=="sion1247",]$area = 'Andean'
area.fixes = matrix(c(
"cent2050","African Savannah",
"maha1287","Indic",
#  "nucl1241","Southeast Asia",  # Li of Baoding
"plat1254","Southeast Asia",
"oroq1238","N Coast Asia",
#  "gela1265","Southeast Asia",
"nucl1655","SE South America",
"west2376","Europe",
"gheg1238","Europe",
"olda1245","Greater Mesopotamia",
"sout2996","Andean",
"pano1254","NE South America",
"chew1245","Oceania",
"chad1240","Southeast Asia",
"zaca1242","Mesoamerica",
"iyow1239","SE South America",
"nort2740","Southeast Asia",
"lang1316","Southeast Asia",
"limo1249","Mesoamerica",
"maon1241","Southeast Asia",
"nege1244","Mesoamerica",
"noot1238","Alaska-Oregon",
"polc1243","African Savannah",
"sout2746","Southeast Asia",
"tokh1242","Europe",
"tokh1243","Europe",
"trin1274","NE South America",
"yavi1244","NE South America",
"minz1236","Southeast Asia"
),nrow=2)
area.fixes = area.fixes[,area.fixes[1,] %in% l.details$glotto]
for(i in 1:ncol(area.fixes)){
l.details[l.details$glotto == area.fixes[1,i],]$area = area.fixes[2,i]
}
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors=F)
g$fam = g[match(g$family_pk,g$pk),]$name
g$fam[is.na(g$family_pk)] = g$name[is.na(g$family_pk)]
rownames(g) = g$id
l.details$family = g[match(l.details$glotto, g$id),]$fam
l.details$latitude = g[l.details$glotto,]$latitude
l.details$longitude = g[l.details$glotto,]$longitude
#l.details[!is.na(l.details$glotto) & l.details$glotto=='nucl1241',c("longitude","latitude")] = c(115.33,38.87)
geo.fix =matrix(c(
# glotto   #lat  #long
'nucl1241',38.87, 115.33,
"olda1245",42.14,37.11,
"limo1249",18.13, -77.26,
"nuuc1236",47.4623893,-118.3132951,
"gela1265",22.56, 104.70,
"roma1329",49.6558485,18.0328078,
"anga1295",-22.11, -58.91,
"kami1255",25.89, 109.22,
"tokh1242",40.333402, 87.248417,
"tokh1243",39.5708233,71.3739565,
"oldh1241",51.0851933,5.9698196,
"west2376",48.090278, 17.97,
'sout1528',21.92, 44.32,
'east2283', 45, 40,
'west2348', 45, 40,
'sout2745', 102.99,14.33,
'east1436', 83.39,27.87
),nrow=3)
geo.fix = geo.fix[,geo.fix[1,] %in% l.details$glotto]
for(i in 1:ncol(geo.fix)){
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$latitude = geo.fix[2,i]
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$longitude = geo.fix[3,i]
}
wals = read.csv("../Analysis/SubjectVerbOrder/wals-language.csv/language.csv", stringsAsFactors = F, fileEncoding = 'utf-8')
wals$glottocode[!is.na(wals$glottocode) & wals$glottocode==''] = NA
l.details$WALS.qpos = wals[match(l.details$glotto, wals$glottocode),]$X93A.Position.of.Interrogative.Phrases.in.Content.Questions
l.details$WALS.qpos[l.details$WALS.qpos==''] = NA
c.grammars = read.csv("../RAW_data/Grammars.csv", stringsAsFactors = F)
c.grammars[c.grammars$Positioning=='',]$Positioning = NA
c.grammars[c.grammars$Possible.Positioning=='',]$Possible.Positioning = NA
c.grammars[is.na(c.grammars$Possible.Positioning),]$Possible.Positioning = c.grammars[is.na(c.grammars$Possible.Positioning),]$Positioning
c.grammars[!c.grammars$Glotto %in% l.details$glotto,c("X",'IDS',"Glotto")]
l.details$S.qpos = c.grammars[match(l.details$glotto, c.grammars$Glotto),]$Possible.Positioning
l.details$qpos = l.details$WALS.qpos
l.details[is.na(l.details$qpos),]$qpos = l.details[is.na(l.details$qpos),]$S.qpos
write.csv(l.details, file="../Analysis/LangsInAnalysis_withGeoData.csv", fileEncoding = 'utf-8', row.names = F)
l.details = read.csv("../Analysis/LangsInAnalysis_withGeoData.csv", fileEncoding = "utf-8", stringsAsFactors = F)
l.details[l.details$qpos=="1 Initial interrogative phrase" & !is.na(l.details$qpos) & l.details$qpos!="",]$glotto
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Processing"))
l.details = read.csv("../Analysis/LangsInAnalysis.csv", fileEncoding = 'utf-8', encoding = 'utf-8', stringsAsFactors = F)
l.details$area = NA
load("~/Documents/MPI/Neandertals_Collab/fossilSept/pca.per.family/autotyp2015-06-09T09-00.rData")
areas = tapply(as.character(autotyp.geography$area),as.character(autotyp.geography$glottolog_LID.2014),head,n=1)
#l.details$area[nchar(l.details$area)<2] = NA
l.details$area = areas[l.details$glotto]
l.details[l.details$glotto=="sout2746",]$area = 'Southeast Asia'
l.details[l.details$glotto=="enap1235",]$area = 'NE South America'
l.details[l.details$glotto=="sion1247",]$area = 'Andean'
area.fixes = matrix(c(
"cent2050","African Savannah",
"maha1287","Indic",
#  "nucl1241","Southeast Asia",  # Li of Baoding
"plat1254","Southeast Asia",
"oroq1238","N Coast Asia",
#  "gela1265","Southeast Asia",
"nucl1655","SE South America",
"west2376","Europe",
"gheg1238","Europe",
"olda1245","Greater Mesopotamia",
"sout2996","Andean",
"pano1254","NE South America",
"chew1245","Oceania",
"chad1240","Southeast Asia",
"zaca1242","Mesoamerica",
"iyow1239","SE South America",
"nort2740","Southeast Asia",
"lang1316","Southeast Asia",
"limo1249","Mesoamerica",
"maon1241","Southeast Asia",
"nege1244","Mesoamerica",
"noot1238","Alaska-Oregon",
"polc1243","African Savannah",
"sout2746","Southeast Asia",
"tokh1242","Europe",
"tokh1243","Europe",
"trin1274","NE South America",
"yavi1244","NE South America",
"minz1236","Southeast Asia"
),nrow=2)
area.fixes = area.fixes[,area.fixes[1,] %in% l.details$glotto]
for(i in 1:ncol(area.fixes)){
l.details[l.details$glotto == area.fixes[1,i],]$area = area.fixes[2,i]
}
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors=F)
g$fam = g[match(g$family_pk,g$pk),]$name
g$fam[is.na(g$family_pk)] = g$name[is.na(g$family_pk)]
rownames(g) = g$id
l.details$langFam = g[match(l.details$glotto, g$id),]$fam
l.details$latitude = g[l.details$glotto,]$latitude
l.details$longitude = g[l.details$glotto,]$longitude
#l.details[!is.na(l.details$glotto) & l.details$glotto=='nucl1241',c("longitude","latitude")] = c(115.33,38.87)
geo.fix =matrix(c(
# glotto   #lat  #long
'nucl1241',38.87, 115.33,
"olda1245",42.14,37.11,
"limo1249",18.13, -77.26,
"nuuc1236",47.4623893,-118.3132951,
"gela1265",22.56, 104.70,
"roma1329",49.6558485,18.0328078,
"anga1295",-22.11, -58.91,
"kami1255",25.89, 109.22,
"tokh1242",40.333402, 87.248417,
"tokh1243",39.5708233,71.3739565,
"oldh1241",51.0851933,5.9698196,
"west2376",48.090278, 17.97,
'sout1528',21.92, 44.32,
'east2283', 45, 40,
'west2348', 45, 40,
'sout2745', 102.99,14.33,
'east1436', 83.39,27.87
),nrow=3)
geo.fix = geo.fix[,geo.fix[1,] %in% l.details$glotto]
for(i in 1:ncol(geo.fix)){
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$latitude = geo.fix[2,i]
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$longitude = geo.fix[3,i]
}
wals = read.csv("../Analysis/SubjectVerbOrder/wals-language.csv/language.csv", stringsAsFactors = F, fileEncoding = 'utf-8')
wals$glottocode[!is.na(wals$glottocode) & wals$glottocode==''] = NA
l.details$WALS.qpos = wals[match(l.details$glotto, wals$glottocode),]$X93A.Position.of.Interrogative.Phrases.in.Content.Questions
l.details$WALS.qpos[l.details$WALS.qpos==''] = NA
c.grammars = read.csv("../RAW_data/Grammars.csv", stringsAsFactors = F)
c.grammars[c.grammars$Positioning=='',]$Positioning = NA
c.grammars[c.grammars$Possible.Positioning=='',]$Possible.Positioning = NA
c.grammars[is.na(c.grammars$Possible.Positioning),]$Possible.Positioning = c.grammars[is.na(c.grammars$Possible.Positioning),]$Positioning
c.grammars[!c.grammars$Glotto %in% l.details$glotto,c("X",'IDS',"Glotto")]
l.details$S.qpos = c.grammars[match(l.details$glotto, c.grammars$Glotto),]$Possible.Positioning
l.details$qpos = l.details$WALS.qpos
l.details[is.na(l.details$qpos),]$qpos = l.details[is.na(l.details$qpos),]$S.qpos
write.csv(l.details, file="../Analysis/LangsInAnalysis_withGeoData.csv", fileEncoding = 'utf-8', row.names = F)
rm(list=ls())
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
rm(list=ls())
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
rm(list=ls())
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
rm(list=ls())
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
getWordListEntropy(d.wh.m, firstSegment=T)
x=
getWordListEntropy(d.wh.m, firstSegment=T)
x
hist(x)
mean(x)
getWordListEntropy(d.wh.m, firstSegment=F)
x = getWordListEntropy(d.wh.m, firstSegment=F)
mean(x)
length(x)
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
####################################
# Run the permutations#
####################################
#Specifes where Text file with results goes
resultsFile = "../Results/SimplifiedPhonology/ResultsSummary_RandomIndependentSamples.txt"
#Removes old info
cat("permName\tDiffMoreThanZero\tMeanDiff\tNumberOfSamples\tz",file=resultsFile) # clear results file
number.of.perms = 20000
number.of.random.samples = 100# number of sets of random concept sets chosen in the comparison permutation for non-wh concepts.
runComparison.randomSample(d.wh.possible.initial.m,d.wh.possible.non.initial.m,families.d.wh.possible.initial,families.d.wh.possible.non.initial,"InterrogativeOrder/InterrogativeOrder_RandomIndependentSamples_firstSegments",T)
4081/20000
hist(d.wh.possible.initial.m)
hist(getWordListEntropy(d.wh.possible.initial.m,T))
hist(getWordListEntropy(d.wh.possible.non.initial.m,T))
mean(getWordListEntropy(d.wh.possible.non.initial.m,T))
mean(getWordListEntropy(d.wh.possible.initial.m,T))
hist(getWordListEntropy(d.wh.possible.initial.m,T), col=rgb(1,0,0,0.3),border=F,xlim=c(0,1),breaks=20)
hist(getWordListEntropy(d.wh.possible.non.initial.m,T),add=T, col=rgb(0,1,0,0.3),border=F,xlim=c(0,1),breaks=20)
x = getWordListEntropy(d.wh.m, T)
which(x==0)
d.wh.m[,'Aymara']
d.wh.m[,'Selkup']
d.wh.m[,'Yaqui']
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Processing"))
l.details = read.csv("../Analysis/LangsInAnalysis.csv", fileEncoding = 'utf-8', encoding = 'utf-8', stringsAsFactors = F)
l.details$area = NA
load("~/Documents/MPI/Neandertals_Collab/fossilSept/pca.per.family/autotyp2015-06-09T09-00.rData")
areas = tapply(as.character(autotyp.geography$area),as.character(autotyp.geography$glottolog_LID.2014),head,n=1)
#l.details$area[nchar(l.details$area)<2] = NA
l.details$area = areas[l.details$glotto]
l.details[l.details$glotto=="sout2746",]$area = 'Southeast Asia'
l.details[l.details$glotto=="enap1235",]$area = 'NE South America'
l.details[l.details$glotto=="sion1247",]$area = 'Andean'
area.fixes = matrix(c(
"cent2050","African Savannah",
"maha1287","Indic",
#  "nucl1241","Southeast Asia",  # Li of Baoding
"plat1254","Southeast Asia",
"oroq1238","N Coast Asia",
#  "gela1265","Southeast Asia",
"nucl1655","SE South America",
"west2376","Europe",
"gheg1238","Europe",
"olda1245","Greater Mesopotamia",
"sout2996","Andean",
"pano1254","NE South America",
"chew1245","Oceania",
"chad1240","Southeast Asia",
"zaca1242","Mesoamerica",
"iyow1239","SE South America",
"nort2740","Southeast Asia",
"lang1316","Southeast Asia",
"limo1249","Mesoamerica",
"maon1241","Southeast Asia",
"nege1244","Mesoamerica",
"noot1238","Alaska-Oregon",
"polc1243","African Savannah",
"sout2746","Southeast Asia",
"tokh1242","Europe",
"tokh1243","Europe",
"trin1274","NE South America",
"yavi1244","NE South America",
"minz1236","Southeast Asia"
),nrow=2)
area.fixes = area.fixes[,area.fixes[1,] %in% l.details$glotto]
for(i in 1:ncol(area.fixes)){
l.details[l.details$glotto == area.fixes[1,i],]$area = area.fixes[2,i]
}
g = read.csv("~/Documents/MPI/Glottolog/glottolog-languoid.csv/languoid.csv",stringsAsFactors=F)
g$fam = g[match(g$family_pk,g$pk),]$name
g$fam[is.na(g$family_pk)] = g$name[is.na(g$family_pk)]
rownames(g) = g$id
l.details$langFam = g[match(l.details$glotto, g$id),]$fam
l.details$latitude = g[l.details$glotto,]$latitude
l.details$longitude = g[l.details$glotto,]$longitude
#l.details[!is.na(l.details$glotto) & l.details$glotto=='nucl1241',c("longitude","latitude")] = c(115.33,38.87)
geo.fix =matrix(c(
# glotto   #lat  #long
'nucl1241',38.87, 115.33,
"olda1245",42.14,37.11,
"limo1249",18.13, -77.26,
"nuuc1236",47.4623893,-118.3132951,
"gela1265",22.56, 104.70,
"roma1329",49.6558485,18.0328078,
"anga1295",-22.11, -58.91,
"kami1255",25.89, 109.22,
"tokh1242",40.333402, 87.248417,
"tokh1243",39.5708233,71.3739565,
"oldh1241",51.0851933,5.9698196,
"west2376",48.090278, 17.97,
'sout1528',21.92, 44.32,
'east2283', 45, 40,
'west2348', 45, 40,
'sout2745', 102.99,14.33,
'east1436', 83.39,27.87
),nrow=3)
geo.fix = geo.fix[,geo.fix[1,] %in% l.details$glotto]
for(i in 1:ncol(geo.fix)){
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$latitude = geo.fix[2,i]
l.details[!is.na(l.details$glotto) & l.details$glotto == geo.fix[1,i],]$longitude = geo.fix[3,i]
}
wals = read.csv("../Analysis/SubjectVerbOrder/wals-language.csv/language.csv", stringsAsFactors = F, fileEncoding = 'utf-8')
wals$glottocode[!is.na(wals$glottocode) & wals$glottocode==''] = NA
l.details$WALS.qpos = wals[match(l.details$glotto, wals$glottocode),]$X93A.Position.of.Interrogative.Phrases.in.Content.Questions
l.details$WALS.qpos[l.details$WALS.qpos==''] = NA
c.grammars = read.csv("../RAW_data/Grammars.csv", stringsAsFactors = F)
c.grammars[c.grammars$Positioning=='',]$Positioning = NA
c.grammars[c.grammars$Possible.Positioning=='',]$Possible.Positioning = NA
c.grammars[is.na(c.grammars$Possible.Positioning),]$Possible.Positioning = c.grammars[is.na(c.grammars$Possible.Positioning),]$Positioning
c.grammars[!c.grammars$Glotto %in% l.details$glotto,c("X",'IDS',"Glotto")]
l.details$S.qpos = c.grammars[match(l.details$glotto, c.grammars$Glotto),]$Possible.Positioning
l.details$qpos = l.details$WALS.qpos
l.details[is.na(l.details$qpos),]$qpos = l.details[is.na(l.details$qpos),]$S.qpos
l.details = l.details[order(l.details$area,l.details$langFam, l.details$Language)]
write.csv(l.details, file="../Analysis/LangsInAnalysis_withGeoData.csv", fileEncoding = 'utf-8', row.names = F)
l.details = l.details[order(l.details$area,l.details$langFam, l.details$Language),]
write.csv(l.details, file="../Analysis/LangsInAnalysis_withGeoData.csv", fileEncoding = 'utf-8', row.names = F)
l.details$area
l.details[is.na(l.details$are),]
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Processing"))
l.details = read.csv("../Analysis/LangsInAnalysis.csv", fileEncoding = 'utf-8', encoding = 'utf-8', stringsAsFactors = F)
l.details$area = NA
load("~/Documents/MPI/Neandertals_Collab/fossilSept/pca.per.family/autotyp2015-06-09T09-00.rData")
areas = tapply(as.character(autotyp.geography$area),as.character(autotyp.geography$glottolog_LID.2014),head,n=1)
#l.details$area[nchar(l.details$area)<2] = NA
l.details$area = areas[l.details$glotto]
l.details[l.details$glotto=="sout2746",]$area = 'Southeast Asia'
l.details[l.details$glotto=="enap1235",]$area = 'NE South America'
l.details[l.details$glotto=="sion1247",]$area = 'Andean'
area.fixes = matrix(c(
"cent2050","African Savannah",
"maha1287","Indic",
#  "nucl1241","Southeast Asia",  # Li of Baoding
"plat1254","Southeast Asia",
"oroq1238","N Coast Asia",
#  "gela1265","Southeast Asia",
"nucl1655","SE South America",
"west2376","Europe",
"gheg1238","Europe",
"olda1245","Greater Mesopotamia",
"sout2996","Andean",
"pano1254","NE South America",
"chew1245","Oceania",
"chad1240","Southeast Asia",
"zaca1242","Mesoamerica",
"iyow1239","SE South America",
"nort2740","Southeast Asia",
"lang1316","Southeast Asia",
"limo1249","Mesoamerica",
"maon1241","Southeast Asia",
"nege1244","Mesoamerica",
"noot1238","Alaska-Oregon",
"polc1243","African Savannah",
"sout2746","Southeast Asia",
"tokh1242","Europe",
"tokh1243","Europe",
"trin1274","NE South America",
"yavi1244","NE South America",
"minz1236","Southeast Asia"
),nrow=2)
area.fixes = area.fixes[,area.fixes[1,] %in% l.details$glotto]
for(i in 1:ncol(area.fixes)){
l.details[l.details$glotto == area.fixes[1,i],]$area = area.fixes[2,i]
}
l.details[is.na(l.details$are),]
l.details[is.na(l.details$are),]$glotto
t(l.details[is.na(l.details$are),]$glotto)
t(t(l.details[is.na(l.details$are),]$glotto))
dim(d.wh.m)
d.wh = alldata[alldata$meaning.id.fixed %in% whwords,]
length(unique(d.wh$Language))
length(unique(d.wh$glotto))
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
dim(d.wh.m)
dim(d.wh)

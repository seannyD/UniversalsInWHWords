t = 50
bp2mm = 2.83467
paste( "pdfcrop --margin '", w*bp2mm, " ",
h*bp2mm," ",
l *bp2mm, " ",
t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margin '",
w*bp2mm, " ",
h*bp2mm," ",
l *bp2mm, " ",
t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --bbox '",
w*bp2mm, " ",
h*bp2mm," ",
l *bp2mm, " ",
t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
w0 = 210
h0 = 297.1
w = 152.4
h = 228.6
l = (w0 - w)/2
t = (h0 - h)/2
bp2mm = 2.83467
paste( "pdfcrop --margins '",
l*bp2mm, " ",
t*bp2mm," ",
l *bp2mm, " ",
t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
w0 = 210
h0 = 297.1
w = 152.4
h = 228.6
l = (w0 - w)/2
t = (h0 - h)/2
bp2mm = 2.83467
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l *bp2mm, " ",
-t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
l
t
-l*bp2mm
595 * (1/2.83467)
l
w0 - (2*l)
paste( "pdfcrop --bbox '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l *bp2mm, " ",
-t *bp2mm, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
l*bp2mm
w0 = 210
h0 = 297.1
w = 152.4
h = 228.6
l = (w0 - w)/2
t = (h0 - h)/2
w0 - (2*l)
bp2mm = 2.83467
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip --bbox '0 0 0 0' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
w0 = 210
h0 = 297.1
w = 152.4
h = 228.6
l = (w0 - w)/2
t = (h0 - h)/2
w0 - (2*l)
bp2mm = 2.83467
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip --bbox '",
0,0,w0*bp2mm,h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
0, " ",
0, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l*bp2mm, " ",
-t*bp2mm, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
w0 = 210
h0 = 297.1
w = 152.35
h = 228.55
l = (w0 - w)/2
t = (h0 - h)/2
w0 - (2*l)
bp2mm = 2.83467
paste( "pdfcrop --margins '",
-l*bp2mm, " ",
-t*bp2mm," ",
-l*bp2mm, " ",
-t*bp2mm, "' --clip --bbox '",
0," ",0," ",w0*bp2mm," ",h0*bp2mm,
"' EvoLang11_test.pdf EvoLang11_crop.pdf",
sep = '')
library(ape)
rtree(10)
t = rtree(10)
d = matrix(rnorm(100),nrow=10)
t
plot(t)
d
d[upper.tri(d)] = d[lower.tri(d)]
diag(d) = 0
library(ecodist)
??patristic
vcov(t)
?vcov
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
source("PermutationTools.r")
n = sample(5:9,1)
x = sample(c('a','b','c','d','e','f','g','h','i'), n, replace = T)
x
n = sample(5:9,1)
x = sample(c('a','b','c','d','e','f','g','h','i'), n, replace = T)
x
d = lapply(1:100, function(){
n = sample(5:9,1)
x = sample(c('a','b','c','d','e','f','g','h','i'), n, replace = T)
})
d = lapply(1:100, function(X){
n = sample(5:9,1)
sample(c('a','b','c','d','e','f','g','h','i'), n, replace = T)
})
d[[1]]
d[[2]]
ef = sapply(d,function(X){
myEntropy(table(X))
})
ef
un = sapply(d, function(X){
length(unique(X))/length(X)
})
plot(ef,un)
un = sapply(d, function(X){
(length(unique(X))+1)/length(X)
})
plot(ef,un)
un = sapply(d, function(X){
(length(unique(X))-1)/length(X)
})
plot(ef,un)
un = sapply(d, function(X){
(length(unique(X))-1)/(length(X)-1)
})
plot(ef,un)
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
source("grammars.R")
source("makeDataVariables.R")
d.wh.glotto = names2glotto[colnames(d.wh.m)]
l.details2 = l.details[l.details$glotto %in% d.wh.glotto,]
l.details2 = l.details2[!duplicated(l.details2$glotto),]
library(maps)
map(interior = F, fill=T, col='gray' )
points(l.details2$longitude,l.details2$latitude,col=rgb(1,0,0),  pch= 16)
library(ggplot2)
set.seed(15)
cols = sample(rainbow(length(unique(l.details2$area)), alpha = 0.75))
l.details2$area.colour = cols[as.numeric(as.factor(l.details2$area))]
l.details2$area.colour[l.details2$area=="Indic"] = 'black'
l.details2$area.colour[l.details2$area=="N Coast Asia"] = 'dark grey'
world <- map_data("world", interior = F)
world <- world[world$region != "Antarctica",]
gg <- ggplot()
gg <- gg + geom_map(data=world, map=world,
aes(x=long, y=lat, map_id=region),
fill="#7f7f7f", size=0.05, alpha=1/4) +
xlab('') + ylab("")
finalMap= gg + geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,color=l.details2$area.colour, size=2)
finalMap
finalMap= gg + geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,color=l.details2$area.colour, size=2) + theme(panel.grid.minor = element_blank())
finalMap
finalMap= gg + geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,color=l.details2$area.colour, size=2) + theme(panel.grid.major = element_blank())
finalMap
finalMap= gg + geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,color=l.details2$area.colour, size=2) + theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
finalMap
gg <- ggplot()
gg <- gg + geom_map(data=world, map=world,
aes(x=long, y=lat, map_id=region),
fill="#7f7f7f", size=0.05, alpha=1/4) +
xlab('') + ylab("") +
scale_x_continuous(expand=c(0,0))
finalMap= gg + geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,color=l.details2$area.colour, size=2) + theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank())
finalMap
finalMap= gg +
geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,
color=l.details2$area.colour, size=2) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.ticks=element_blank())
finalMap
finalMap= gg +
geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,
color=l.details2$area.colour, size=2) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.ticks=element_blank(),
axis.text.y=element_blank())
finalMap
finalMap= gg +
geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,
color=l.details2$area.colour, size=2) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.ticks=element_blank(),
axis.text.y=element_blank(),
axis.text.x=element_blank())
finalMap
?CRS
library(maptools)
?CRS
world <- map_data("world", interior = F)
world <- world[world$region != "Antarctica",]
worldSpP <- map2SpatialPolygons(world, world$names, CRS("+proj=longlat +ellps=WGS84"))
world <- map("world", fill=TRUE, col="transparent", plot=FALSE)
worldSpP <- map2SpatialPolygons(world, world$names, CRS("+proj=longlat +ellps=WGS84"))
worldSpPnr <- nowrapRecenter(worldSpP)
world <- map("world", fill=TRUE, col="transparent", plot=FALSE)
worldSpP <- map2SpatialPolygons(world, world$names, CRS("+proj=longlat +ellps=WGS84"))
worldSpPnr <- nowrapRecenter(worldSpP)
world <- map("world", fill=TRUE, col="transparent", plot=FALSE)
worldSpP <- map2SpatialPolygons(world, world$names, CRS("+proj=longlat +ellps=WGS84"))
world_map <- fortify(worldSpPnr)
world_map <- fortify(worldSpP)
gg <- ggplot()
gg <- gg + geom_map(data=world_map, map=world,
aes(x=long, y=lat, map_id=region),
fill="#7f7f7f", size=0.05, alpha=1/4) +
xlab('') + ylab("")
gg <- ggplot()
gg <- gg + geom_map(data=world_map, map=world_map,
aes(x=long, y=lat, map_id=region),
fill="#7f7f7f", size=0.05, alpha=1/4) +
xlab('') + ylab("")
finalMap= gg +
geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,
color=l.details2$area.colour, size=2) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.ticks=element_blank(),
axis.text.y=element_blank(),
axis.text.x=element_blank())
finalMap
try(setwd("U:/Pragmatics/New/Analysis/"))
try(setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis"))
# load data and filter unwanted languages
# (creates variable 'alldata')
source("RestrictionsApplied.R") # also loads PermutationTools.R
finalMap
world <- map_data("world", interior = F)
world <- world[world$region != "Antarctica",]
gg <- ggplot()
gg <- gg + geom_map(data=world, map=world,
aes(x=long, y=lat, map_id=region),
fill="#7f7f7f", size=0.05, alpha=1/4) +
xlab('') + ylab("")
finalMap= gg +
geom_point(aes(y=l.details2$latitude, x=l.details2$longitude) ,
color=l.details2$area.colour, size=2) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.ticks=element_blank(),
axis.text.y=element_blank(),
axis.text.x=element_blank())
pdf("../Writeup/images/mapOfLanguages.pdf", width=8, height=5)
finalMap
dev.off()
png("../Writeup/images/mapOfLanguages.png", width=800, height=500)
finalMap
dev.off()
finalMap
pdf("../Writeup/images/mapOfLanguages.pdf", width=8, height=4.5)
finalMap
dev.off()
png("../Writeup/images/mapOfLanguages.png", width=800, height=450)
finalMap
dev.off()
library(xtable)
setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis/")
options("scipen"=100, "digits"=7)
getStats3 = function(filenames,base='',label=filenames[1],lessThan=F){
# random independent sample
# test whether differences are greater than zero
#  d = data.frame()
#  for(filename in filenames){
#    d = rbind(d,read.csv(paste(base,filename,sep='')))
#  }
d = do.call(rbind, lapply(paste(base,filenames,sep=''), function(x) read.csv(x, stringsAsFactors = FALSE)))
if(ncol(d)==2){
trueV = mean(d[d$Type=="True",2])
permV = d[d$Type=="Perm",2]
} else{
trueV = 0
permV = d[,1]
}
permV = permV[!is.na(permV)]
meanPerm = mean(permV)
p = sum(trueV >= permV) / length(permV)
if(lessThan){
p = sum(trueV <= permV) / length(permV)
}
if(p==0){
if(length(permV) > 10000 ){
p = "< 0.0001"
} else{
p = paste("<",1/length(permV))
}
} else{
if(p < 0.0001){
p = "< 0.0001"
} else{
p = signif(p,2)
}
}
z.score = (trueV - mean(permV)) / sd(permV)
z.score = round(z.score,2)
meanPerm = signif(meanPerm,2)
filenameLabel = filenames
if(length(filenameLabel)>1){
x = unlist(strsplit(filenameLabel, "_"))
tx = table(x)
tx = tx[tx==max(tx)]
filenameLabel = paste(paste(unique(x[x %in% unique(names(tx))]),collapse='_'),"*",sep='')
}
dx = data.frame(Test=label,filename=filenameLabel,meanPerm=meanPerm,p=p,z=z.score, stringsAsFactors = F)
return(dx)
}
addLine = function(label){
return(data.frame(Test=label,filename="Filename",meanPerm="Mean",p="p",z="z", stringsAsFactors = F))
}
makeTitle = function(label,folder){
return(paste(label," From results folder",folder))
}
makeTable = function(dx, title, baseF, n=172){
return(print(xtable(dx, caption=makeTitle(title,baseF)),include.rownames=FALSE, type='latex'))
}
baseF = "../Results/SimplifiedPhonology/PermutationResults/"
baseF = "../Results/SimplifiedPhonology/PermutationResults/RandomConcepts/RandomConceptPermutationTest/"
files = list.files(baseF)
files =files[grepl("\\.csv",files)]
random2random = rbind(
getStats3(files[grepl("Permutation_allSegments_",files)],baseF,"All segments"),
getStats3(files[grepl("Permutation_firstSegments_",files)],baseF,"First segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_allSegments_",files)],baseF,"Same domain, permute within family, all segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_firstSegments_",files)],baseF,"Same domain, permute within family, first segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_and_Area_allSegments_",files)],baseF,"Same domain, permute within family and area, all segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_and_Area_firstSegments_",files)],baseF,"Same domain, permute within family and area, first segments")
)
t6 = makeTable(random2random, "Similarity of randomly selected concepts within a language, compared to between languages.", baseF)
outFile = "../Results/SimplifiedPhonology/tables/Summary/SummaryTables.tex"
cat( paste(t1,t2,t3,t4,t5,t6,sep="\n"), file=outFile)
library(xtable)
setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/NewAnalysis/Pragmatics_Slonimska/Analysis/")
options("scipen"=100, "digits"=7)
getStats3 = function(filenames,base='',label=filenames[1],lessThan=F){
# random independent sample
# test whether differences are greater than zero
#  d = data.frame()
#  for(filename in filenames){
#    d = rbind(d,read.csv(paste(base,filename,sep='')))
#  }
d = do.call(rbind, lapply(paste(base,filenames,sep=''), function(x) read.csv(x, stringsAsFactors = FALSE)))
if(ncol(d)==2){
trueV = mean(d[d$Type=="True",2])
permV = d[d$Type=="Perm",2]
} else{
trueV = 0
permV = d[,1]
}
permV = permV[!is.na(permV)]
meanPerm = mean(permV)
p = sum(trueV >= permV) / length(permV)
if(lessThan){
p = sum(trueV <= permV) / length(permV)
}
if(p==0){
if(length(permV) > 10000 ){
p = "< 0.0001"
} else{
p = paste("<",1/length(permV))
}
} else{
if(p < 0.0001){
p = "< 0.0001"
} else{
p = signif(p,2)
}
}
z.score = (trueV - mean(permV)) / sd(permV)
z.score = round(z.score,2)
meanPerm = signif(meanPerm,2)
filenameLabel = filenames
if(length(filenameLabel)>1){
x = unlist(strsplit(filenameLabel, "_"))
tx = table(x)
tx = tx[tx==max(tx)]
filenameLabel = paste(paste(unique(x[x %in% unique(names(tx))]),collapse='_'),"*",sep='')
}
dx = data.frame(Test=label,filename=filenameLabel,meanPerm=meanPerm,p=p,z=z.score, stringsAsFactors = F)
return(dx)
}
addLine = function(label){
return(data.frame(Test=label,filename="Filename",meanPerm="Mean",p="p",z="z", stringsAsFactors = F))
}
makeTitle = function(label,folder){
return(paste(label," From results folder",folder))
}
makeTable = function(dx, title, baseF, n=172){
return(print(xtable(dx, caption=makeTitle(title,baseF)),include.rownames=FALSE, type='latex'))
}
baseF = "../Results/SimplifiedPhonology/PermutationResults/"
whAll = rbind(
#addLine("Wh words, all segments"),
getStats3(c("AllLangs_allSegments.csv"),baseF , "All segments"),
getStats3(c("AllLangs_Consonants_allSegments.csv"),baseF,"Consonants"),
getStats3(c("AllLangs_Vowels_allSegments.csv"),baseF,"Vowels"),
getStats3("AllLangs_allSegments_byFamily.csv",baseF,"Permute within families"),
getStats3("AllLangs_allSegments_byArea.csv",baseF,"Permute within areas"),
getStats3("AllLangs_allSegments_byAreaAndFamily.csv",baseF,"Permute within families andareas"),
getStats3("AllLangs_unanalyzable_allSegments.csv",baseF,"Unanalysable words"),
getStats3("AllLangs_unanalyzable_allSegments_byFamily.csv",baseF,"Unanalysable words, permute within families"),
getStats3("AllLangs_unanalyzable_allSegments_byArea.csv",baseF,"Unanalysable words, permute within areas"),
getStats3("AllLangs_unanalyzable_allSegments_byAreaAndFamily.csv",baseF,"Unanalysable words, permute within families and areas")
)
t1 = makeTable(whAll, "Results for wh words, all segments",baseF,172)
wh1st = rbind(
# addLine("Wh words, first segments"),
getStats3(c("AllLangs_firstSegments.csv"),baseF , "All segments"),
getStats3(c("AllLangs_Consonants_firstSegments.csv"),baseF,"Consonants"),
getStats3(c("AllLangs_Vowels_firstSegments.csv"),baseF,"Vowels"),
getStats3("AllLangs_firstSegment_byFamily.csv",baseF,"Permute within families"),
getStats3("AllLangs_firstSegment_byArea.csv",baseF,"Permute within areas"),
getStats3("AllLangs_firstSegment_byAreaAndFamily.csv",baseF,"Permute within families andareas"),
getStats3("AllLangs_unanalyzable_firstSegments.csv",baseF,"Unanalysable words"),
getStats3("AllLangs_unanalyzable_firstSegment_byFamily.csv",baseF,"Unanalysable words, permute within families"),
getStats3("AllLangs_unanalyzable_firstSegment_byArea.csv",baseF,"Unanalysable words, permute within areas"),
getStats3("AllLangs_unanalyzable_firstSegment_byAreaAndFamily.csv",baseF,"Unanalysable words, permute within families and areas")
)
t2 = makeTable(wh1st, "Results for wh words, first segments",baseF,172)
action = rbind(
# addLine("Basic action words"),
getStats3("AllLangs_allSegments_ActionDomain.csv",baseF , "All segments"),
getStats3("AllLangs_firstSegments_ActionDomain.csv",baseF , "First segments"),
getStats3("AllLangs_allSegments_BasicActionsDomain_byFamilyAndArea.csv", baseF, "All segments, permute within families and areas"),
getStats3("AllLangs_firstSegments_BasicActionsDomain_byFamilyAndArea.csv", baseF, "First segments, permute within families and areas")
)
t3 = makeTable(action, "Results for basic action words",baseF,172)
body = rbind(
#addLine("Body words"),
getStats3("AllLangs_allSegments_BodyDomain.csv",baseF , "All segments"),
getStats3("AllLangs_firstSegments_BodyDomain.csv",baseF , "First segments"),
getStats3("AllLangs_allSegments_BodyDomain_byFamilyAndArea.csv", baseF, "All segments, permute within families and areas"),
getStats3("AllLangs_firstSegments_BodyDomain_byFamilyAndArea.csv", baseF, "First segments, permute within families and areas")
)
t4 = makeTable(body, "Results for body words",baseF,172)
pronoun = rbind(
# addLine("Pronouns"),
getStats3("AllLangs_allSegments_Pronouns.csv",baseF , "All segments"),
getStats3("AllLangs_firstSegments_Pronouns.csv",baseF , "First segments"),
getStats3("AllLangs_allSegments_PronounDomain_byFamilyAndArea.csv", baseF, "All segments, permute within families and areas"),
getStats3("AllLangs_allSegments_PronounDomain_byFamilyAndArea.csv", baseF, "First segments, permute within families and areas")
)
t5 = makeTable(pronoun, "Results for pronouns",baseF,172)
baseF = "../Results/SimplifiedPhonology/PermutationResults/RandomConcepts/RandomConceptPermutationTest/"
files = list.files(baseF)
files =files[grepl("\\.csv",files)]
random2random = rbind(
getStats3(files[grepl("Permutation_allSegments_",files)],baseF,"All segments"),
getStats3(files[grepl("Permutation_firstSegments_",files)],baseF,"First segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_allSegments_",files)],baseF,"Same domain, permute within family, all segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_firstSegments_",files)],baseF,"Same domain, permute within family, first segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_and_Area_allSegments_",files)],baseF,"Same domain, permute within family and area, all segments"),
getStats3(files[grepl("Permutation_Domain_byFamily_and_Area_firstSegments_",files)],baseF,"Same domain, permute within family and area, first segments")
)
t6 = makeTable(random2random, "Similarity of randomly selected concepts within a language, compared to between languages.", baseF)
outFile = "../Results/SimplifiedPhonology/tables/Summary/SummaryTables.tex"
cat( paste(t1,t2,t3,t4,t5,t6,sep="\n"), file=outFile)
